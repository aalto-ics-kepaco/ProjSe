######################
## Version 0.1 #######
######################
import sys, time

import numpy as np

import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import colorConverter

## ##########################################
# import selection_by_projectors as projector_lin
import ProjSe as projector_kern

## #################################
## #################################
## ##########################################
## ##########################################
## Utility functions
## ##########################################
def centr_data(X):
  """
  Task: data centralization by column mean
  """
  
  xmean = np.mean(X,0)
  ## X -= np.outer(np.ones(X.shape[0]),xmean)
  X -= xmean
  
  return(X)

## #################################
def norm_data(X):
  """
  Task: data normalization by L_2 norm row wise
  """
  
  xnorm = np.sqrt(np.sum(X**2,1))
  xnorm += 1*(xnorm==0)
  ## X /= np.outer(xnorm,np.ones(X.shape[1]))
  X = (X.T/xnorm).T
  
  return(X)

## ########################################
def random_data(m, n, ny = None, rng = None, W = None, snoise = 1, \
                iregdegree = 1, ivarscale = 0, ilintransform = 0):
  """
  Task: to construct a random X, Y matrix pairs
        where Y is related to X by regression,
        and random noise can be added to Y as well.
  Input:
         m              number of examples
         n              number of input variables
         ny             number of output variables
         rng            reference to numpy random number generator
         W              regression transformation matrix
         snoise         =1 noise is added, =0 not
         iregdegree     =1 linear, =2 quadratic regression
         ivarscale      =1 random variance scaling, =0 not
         ilintransform  =1 random linear transformation of the input, =0 not
  Output:
         list = [2d array of input examples in the rows,
                       2d array of output examples in the rows]
  """ 

  if rng is None:
    rng = np.random.default_rng()

  if ny is None:
    ny = n
      
  if iregdegree == 1:
    ## the variables to be selected in the columns
    X=rng.standard_normal(size=(m,n))  
    ## @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
    if ivarscale == 1:
      s = np.linspace(0.1,10,num=n)
      X=X*s   ## scaling the variable variances
    if ilintransform == 1:
      A = rng.standard_normal(size=(n,n))
      X = np.dot(X,A)  ## random linear transfrormation
    ## @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
    X=centr_data(X)                      
    X=norm_data(X)
    if W is None:
      W=rng.standard_normal(size=(n,ny))  ## linear mapping
    Y=np.dot(X,W)           ## reference variables 
    ## generate noise and randomly scaling them using linspace
    noise = snoise * rng.standard_normal(size=(m, ny))
    Y += noise
    # Add random noise by Y += np.random.round(Y.shape)
  if iregdegree == 2:  ## quadratic case
    ## the variables to be selected in the columns
    X=rng.standard_normal(size=(m,n))  
    if ivarscale == 1:
      s = np.linspace(0.1,10,num=n)
      X=np.dot(X,np.diag(s))   ## scaling the variable variances
    if ilintransform == 1:
      A = rng.standard_normal(size=(n,ny))
      X = np.dot(X,A)  ## random linear transfrormation
    Xquad = np.zeros((m,(n+1)*n/2))
    ij = 0
    for i in range(n):
      for j in range(i,n):
        Xquad[:,ij] = X[:,i]*X[:,j]
        ij += 1
    X = np.hstack((np.ones((m,1)),X,Xquad))
    ## @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
    X=centr_data(X)                      
    X=norm_data(X)
    if W is None:
      W=rng.standard_normal(size=(X.shape[1],ny))  ## linear mapping
    Y=np.dot(X,W)           ## reference variables 
    ## generate noise and randomly scaling them using linspace
    noise = snoise * rng.standard_normal(size=(m, ny))
    Y += noise
    # Add random noise by Y += np.random.round(Y.shape)

  return([X,Y])  

## ##########################################
## #################################
def main(workmode):
  """
  Task: an example code of the projection based selection
  """

  igraph = 1            ## =1 graph is drawn, =0 not

  ## test environment
  mblock = 10000      ## example block size
  nblock = 10           ## number of example blocks
  mvar = 10             ## variable block size
  nvar = 10             ## number of variable blocks
  m = mblock * nblock   ## number of total examples  
  n = mvar*nvar         ## number of total variables

  nsample = 2           ## nuber of random samples
  
  rng = np.random.default_rng(1234)

  ilinreg = 1           ## random data generated by linear regression         
  ## @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
  ilintransform = 0     ## random linear transformation of the input X
  ivarscale = 0         ## random scaling of the variable variances
  ## @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
  irowcol = 0   ## =0 example number  iteration, =1 variable number iteration
  
  if irowcol == 0:
    ilow = mblock
    ihigh = m+1
    istep = mblock
  elif irowcol == 1:
    ilow = mvar
    ihigh = n+1
    istep = mvar

  # times_lin = []
  times_kern = []

  for i in range(ilow, ihigh, istep):
    ## data generation
    print('Data generation')
    if irowcol == 0:
      lXY = random_data(i, n, ny = n, rng = rng, iregdegree = ilinreg, \
        ivarscale = ivarscale, ilintransform = ilintransform)
    elif irowcol == 1:
      lXY = random_data(m, i, ny = i, rng = rng, iregdegree = ilinreg, \
        ivarscale = ivarscale, ilintransform = ilintransform)

    ## @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
    ## the input variable selection procedure
    ## original variable selection algorithm
    if irowcol == 0:
      nselected = n  ## number of variables to be selected
    elif irowcol == 1:
      nselected = i  ## number of variables to be selected

    ## @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
    ## the input variable selection procedure
    ## kernelized recursive variable selection algorith
    ## construct the object
    print('Selection')
    # cproject=projector_kern.cls_projector_kern(func_kern \
    #   = kern_func_gaussian) 
    cproject=projector_kern.cls_projector_kern(func_kern \
      = None) 
    time0 = time.time()
    ## run the selection
    lorder_kern=cproject.full_cycle(lXY[1],lXY[0],nselected, ilocal = 1, \
      iscale = 1)
    time_kern = time.time()-time0
    ## collect the number of examples,
    ##    the number of variables,
    ##    computation time
    ##    list of indexes of selected variables, first is the best
    ##    list of correlation values corresponding to the selected variables 
    times_kern.append((lXY[0].shape[0],lXY[0].shape[1],time_kern, \
                      lorder_kern,cproject.xstat))
    print('Iteration:',i,'Kernel selection time:',time_kern)
    ## @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
    del lXY[1]
    del lXY[0]

  ntimes = len(times_kern)
  if irowcol == 0:
    xtimese = np.array([ times_kern[i][2] for i in range(ntimes)] )  
    xexamples = np.array([ times_kern[i][0] for i in range(ntimes)] )
    xselected = times_kern[ntimes-1][3]
    xscores = times_kern[ntimes-1][4]
  else:
    xtimesv = np.array([ times_kern[i][2] for i in range(ntimes)] )  
    xvariables = np.array([ times_kern[i][1] for i in range(ntimes)] )    
    xselected = times_kern[ntimes-1][3]
    xscores = times_kern[ntimes-1][4]
  
  if igraph == 1:
    fig = plt.figure(figsize=(10,5))
    if irowcol == 0:
      fig.suptitle('Selection time on examples' + '\n' \
                   +'number of variables:'+str(n)) 
    elif irowcol == 1:
      fig.suptitle('Selection time on variables' + '\n' \
                   +'number of examples:'+str(m))

    plotgrid=(1,2)
    nshown = 10  ## number of selected variables with the highest correlations 

    if irowcol == 0:

      ax=plt.subplot2grid(plotgrid,(0,0),colspan=1,rowspan=1)

      ax.plot(xexamples,xtimese, label = 'times(s)')
      ax.set_xlabel('Number of examples',fontsize = 12)
      ax.set_title('Running time on sample sizes')
      ax.set_xticks(xexamples)
      ax.set_xticklabels([str(v) for v in xexamples ], \
                         rotation = 30 )
      ax.set_ylabel('Time(s)')
      ax.legend()
      ax.grid(True,ls='--')

      ax=plt.subplot2grid(plotgrid,(0,1),colspan=1,rowspan=1)
      ax.plot(xscores[:nshown], label = 'scores')
      ax.set_xlabel('Index of first 10 selected variables',fontsize = 12)
      ax.set_title('Correlation values on the largest sample')
      ax.set_xticks([ ivar for ivar in range(nshown)])
      ax.set_xticklabels([str(xselected[ivar]) for ivar in range(nshown)], \
                         rotation = 30 )
      ax.set_ylabel('Correlation values')
      ax.legend()
      ax.grid(True,ls='--')
      

    elif irowcol == 1:

      ax=plt.subplot2grid(plotgrid,(0,0),colspan=1,rowspan=1)
      ax.plot(xvariables,xtimesv, label = 'times(s)')
      ax.set_xlabel('Number of variables')
      # ax.set_title('Running time on different number of variables, ' \
      #              +'\n'+'sample size:'+str('%7d'%m))
      ax.set_xticks(xvariables)
      ax.set_xticklabels([str(v) for v in xvariables ], rotation = 30, \
                         fontsize=10 )

      ax.set_ylabel('Time(s)')
      ax.legend()
      ax.grid(True,ls='--')

      ax=plt.subplot2grid(plotgrid,(0,1),colspan=1,rowspan=1)
      ax.plot(xscores[:nshown], label = 'scores')
      ax.set_xlabel('Index of first 10 selected variables',fontsize = 12)
      ax.set_title('Correlation values on the largest sample')
      ax.set_xticks([ ivar for ivar in range(nshown)])
      ax.set_xticklabels([str(xselected[ivar]) for ivar in range(nshown)], \
                         rotation = 30 )
      ax.set_ylabel('Correlation values')
      ax.legend()
      ax.grid(True,ls='--')
      
      
    plt.tight_layout(pad=1)
    plt.show()

  print('Bye')
  
  return
  
## ################################################################
if __name__ == "__main__":
  if len(sys.argv)==1:
    iworkmode=0
  elif len(sys.argv)>=2:
    iworkmode=eval(sys.argv[1])
  # for i in range(2, 10, 2):
  #   main(iworkmode, i/10.0)
  main(iworkmode)
